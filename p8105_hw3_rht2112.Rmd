---
title: "Homework 3"
author: Rachel Tao
output: github_document
---

```{r setup}

library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` and `r ncol(instacart)` columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. Make sure to convey structure of the data.

How many aisles, and which are most items from?

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

134 aisles, most come from fresh vegetables and fresh fruits.

Let's make a plot

```{r eval=FALSE}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Let's make a table

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Apples vs. ice cream

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

## Problem 2

Read in and tidy accel_data.csv

```{r}
accel <- read_csv("./data/accel_data.csv") %>%
  pivot_longer(
    activity.1:activity.1440,
    names_to = "min",
    names_prefix = "activity.",
    values_to = "activity_count"
  )

week_df <- 
  tibble(
    weekday = c(1,2,3,4,5,6,7),
    day = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
  )

accel <- 
  left_join(accel, week_df, by = "day") %>% 
  arrange(week, weekday, .by_group = TRUE) %>% 
  mutate(
    day_type = 
      as.factor(ifelse(day %in% c("Saturday", "Sunday"), "weekend", "weekday")),
    day = 
      as.factor(day),
    min =
      as.integer(min),
    hour = 
      min %% 24,
    week =
      as.factor(week)
  ) %>% 
  relocate(day_id, week, day, day_type, hour, min) %>% 
  select(-weekday)

```

Describe the dataset above. 

Aggregate minutes to days

```{r}
accel %>% 
  group_by(week, day) %>% 
  summarize(activity_count_day = sum(activity_count)) %>% 
  arrange(week, day) %>% 
  knitr::kable(digits = 1)
#why isn't this table in correct weekday order?
```

Trends?

Create a plot showing how activity count changes over the course of the dayfor each day of the week.

```{r}
accel %>% 
  group_by(week, day, hour) %>% 
  mutate(
    activity_count_hour = 
      sum(activity_count)
  ) %>% 
  ggplot(aes(x = hour, y = activity_count_hour, color = day)) +
  geom_smooth()
#why are the weekdays in a weird order still?
#format labels to be a little nicer
```

# Problem 3

```{r}
data("ny_noaa")
```

```{r}
ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = ) %>% 
  mutate(
    year =
      as.numeric(year),
    month =
      as.numeric(month),
    day = 
      as.numeric(day),
    prcp =
      10*prcp,
    tmax =
      10*(as.numeric(tmax)),
    tmin =
      10*(as.numeric(tmin))
  )
#how best to assess missingness?
```

Snow

```{r}
ny_noaa %>% 
  count(snow) %>% 
  arrange(-n)
```

The most commonly observed values are 0 and NA. This is because for most days of the year, there is not snow.
